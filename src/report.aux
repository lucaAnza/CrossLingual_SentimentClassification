\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction and Problem Presentation}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Task description}{2}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces End-to-end sentiment analysis pipeline. An Amazon review is processed by the model tokenizer, mapped to embeddings, encoded by a transformer model, and passed to a task-specific prediction head.}}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sentiment_pipeline}{{1}{2}{End-to-end sentiment analysis pipeline. An Amazon review is processed by the model tokenizer, mapped to embeddings, encoded by a transformer model, and passed to a task-specific prediction head}{figure.caption.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Project goal and research questions}{2}{subsection.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Why the problem is challenging}{2}{subsection.1.3}\protected@file@percent }
\citation{kaggle_amazon_multilingual}
\@writefile{toc}{\contentsline {section}{\numberline {2}Method}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Computing resources (Hardware)}{4}{subsection.2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Hardware configuration used for model training and evaluation.}}{4}{table.caption.2}\protected@file@percent }
\newlabel{tab:hardware}{{1}{4}{Hardware configuration used for model training and evaluation}{table.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Software stack (Frameworks and tools)}{4}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Dataset overview}{4}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Data fields}{4}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Overview of the main fields in the Amazon Reviews dataset.}}{4}{table.caption.3}\protected@file@percent }
\newlabel{tab:dataset_fields}{{2}{4}{Overview of the main fields in the Amazon Reviews dataset}{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Label distribution}{5}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Label distribution in the training set (balanced).}}{5}{table.caption.4}\protected@file@percent }
\newlabel{tab:label_distribution_train}{{3}{5}{Label distribution in the training set (balanced)}{table.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Dataset split sizes}{5}{subsubsection.2.3.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Overview of dataset splits used in the experiments.}}{5}{table.caption.5}\protected@file@percent }
\newlabel{tab:dataset_splits}{{4}{5}{Overview of dataset splits used in the experiments}{table.caption.5}{}}
\citation{sanh2019distilbert}
\citation{wolf2020transformers}
\citation{hf_distilbert_multilingual}
\citation{hf_distilbert_multilingual}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Model choice}{6}{subsection.2.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Main characteristics of the \texttt  {distilbert-base-multilingual-cased} model \cite  {hf_distilbert_multilingual}}}{6}{table.caption.6}\protected@file@percent }
\newlabel{tab:model_features}{{5}{6}{Main characteristics of the \texttt {distilbert-base-multilingual-cased} model \cite {hf_distilbert_multilingual}}{table.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Preprocessing and input representation}{6}{subsection.2.5}\protected@file@percent }
\newlabel{column-selection}{{2.5}{6}{Column selection}{section*.7}{}}
\@writefile{toc}{\contentsline {paragraph}{Column selection.}{6}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Tokenization.}{6}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Model vocabulary.}{6}{section*.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example tokenization of Amazon review sentences in different languages using the \texttt  {distilbert-base-multilingual-cased} tokenizer. The figure shows how a shared multilingual subword vocabulary is used across languages.}}{7}{figure.caption.10}\protected@file@percent }
\newlabel{fig:tokenization_examples}{{2}{7}{Example tokenization of Amazon review sentences in different languages using the \texttt {distilbert-base-multilingual-cased} tokenizer. The figure shows how a shared multilingual subword vocabulary is used across languages}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Label normalization.}{7}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Training setup}{7}{subsection.2.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces Key training hyperparameters used in the experiments.}}{7}{table.caption.12}\protected@file@percent }
\newlabel{tab:training_hyperparameters}{{6}{7}{Key training hyperparameters used in the experiments}{table.caption.12}{}}
\@writefile{toc}{\contentsline {paragraph}{Hyperparameter selection.}{7}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7}Evaluation metrics}{8}{subsection.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.1}Regression setting.}{8}{subsubsection.2.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.7.2}Classification setting.}{8}{subsubsection.2.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8}Experiment protocol}{8}{subsection.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.1}Regression vs Classification}{8}{subsubsection.2.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.2}How much target-language data is needed}{9}{subsubsection.2.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.3}How much target-language data is needed}{9}{subsubsection.2.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.4}One multilingual model vs. monolingual models: Which works better?}{9}{subsubsection.2.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.8.5}Per-language performance ranking}{10}{subsubsection.2.8.5}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{HIMANSHU or ALBERTO}{10}{section*.14}\protected@file@percent }
\pgfsyspdfmark {pgfid1}{4661699}{43414759}
\pgfsyspdfmark {pgfid4}{37068865}{43428215}
\pgfsyspdfmark {pgfid5}{38985793}{43183029}
\@writefile{toc}{\contentsline {section}{\numberline {3}Results}{11}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.0.1}Regression vs Classification}{11}{subsubsection.3.0.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces Comparison between regression and classification}}{11}{table.caption.15}\protected@file@percent }
\newlabel{tab:regression_vs_classification}{{7}{11}{Comparison between regression and classification}{table.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.0.2}Qualitative Comparison}{11}{subsubsection.3.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Regression}{11}{section*.16}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Classification}{12}{section*.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.0.3}Results about dataset size}{12}{subsubsection.3.0.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces Impact of dataset size on regression performance}}{12}{table.caption.18}\protected@file@percent }
\newlabel{tab:best_dataset_size}{{8}{12}{Impact of dataset size on regression performance}{table.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Epoch related to the dataset size}}{12}{figure.caption.19}\protected@file@percent }
\newlabel{fig:epoch_comparison}{{3}{12}{Epoch related to the dataset size}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces QWK metrics}}{13}{figure.caption.20}\protected@file@percent }
\newlabel{fig:qwk_regression}{{4}{13}{QWK metrics}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Spearman metrics}}{13}{figure.caption.21}\protected@file@percent }
\newlabel{fig:spearman_regression}{{5}{13}{Spearman metrics}{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces RMSE metrics}}{13}{figure.caption.22}\protected@file@percent }
\newlabel{fig:rmse_regression}{{6}{13}{RMSE metrics}{figure.caption.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.0.4}One multilingual model vs. monolingual models}{14}{subsubsection.3.0.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Training loss comparison between multilingual and monolingual models. The multilingual model (in pink) shows slower convergence compared to the single-language model (in purple).}}{14}{figure.caption.23}\protected@file@percent }
\newlabel{fig:train_loss}{{7}{14}{Training loss comparison between multilingual and monolingual models. The multilingual model (in pink) shows slower convergence compared to the single-language model (in purple)}{figure.caption.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces Comparison of Multilingual and Single Language (German) Models on the Same Dataset (either Multilingual or English-only).}}{14}{table.caption.24}\protected@file@percent }
\newlabel{tab:model_comparison}{{9}{14}{Comparison of Multilingual and Single Language (German) Models on the Same Dataset (either Multilingual or English-only)}{table.caption.24}{}}
\@writefile{toc}{\contentsline {paragraph}{Model Evaluation on German Test Set}{14}{section*.25}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces Comparison of Multilingual and Single Language Models Evaluated on a Test Set of 5000 German Reviews.}}{15}{table.caption.26}\protected@file@percent }
\newlabel{tab:test_set_comparison}{{10}{15}{Comparison of Multilingual and Single Language Models Evaluated on a Test Set of 5000 German Reviews}{table.caption.26}{}}
\@writefile{toc}{\contentsline {paragraph}{Model Evaluation on Cross-Lingual Test Set}{15}{section*.27}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces Comparison of Multilingual and Single Language Models Evaluated on a Cross-Lingual Test Set (1000 Reviews, Excluding German).}}{15}{table.caption.28}\protected@file@percent }
\newlabel{tab:cross_lingual_comparison}{{11}{15}{Comparison of Multilingual and Single Language Models Evaluated on a Cross-Lingual Test Set (1000 Reviews, Excluding German)}{table.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Errors by language for the Single Language Model.}}{15}{figure.caption.29}\protected@file@percent }
\newlabel{fig:single_language_errors}{{8}{15}{Errors by language for the Single Language Model}{figure.caption.29}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Errors by language for the Multilingual Model.}}{16}{figure.caption.30}\protected@file@percent }
\newlabel{fig:multilingual_errors}{{9}{16}{Errors by language for the Multilingual Model}{figure.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{17}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Key findings}{17}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Multilingual vs Monolingual Models}{17}{section*.31}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{18}{section.5}\protected@file@percent }
\bibcite{devlin2019bert}{1}
\bibcite{sanh2019distilbert}{2}
\bibcite{wolf2020transformers}{3}
\bibcite{wandb}{4}
\bibcite{kaggle_amazon_multilingual}{5}
\bibcite{hf_distilbert_multilingual}{6}
\@writefile{toc}{\contentsline {section}{\numberline {A}Reflection with respect to learning objectives}{19}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B}Work tasks distribution}{19}{appendix.B}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Work distribution}}{19}{table.caption.33}\protected@file@percent }
\gdef \@abspage@last{19}
